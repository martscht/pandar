---
title: Tests für abhängige Stichproben - Lösungen
type: post
date: '2022-12-13'
slug: gruppenvergleiche-abhaengig-loesungen
categories: Statistik I Übungen
tags: []
subtitle: ''
summary: ''
authors:
- walter
- nehler
lastmod: '`r Sys.Date()`'
featured: no
banner:
  image: /header/consent_checkbox.jpg
  caption: '[Courtesy of pxhere](https://pxhere.com/en/photo/449195)'
projects: []
_build:
  list: never
reading_time: no
share: no
links:
- icon_pack: fas
  icon: book
  name: Inhalte
  url: /lehre/statistik-i/gruppenvergleiche-abhaengig
- icon_pack: fas
  icon: pen-to-square
  name: Übungen
  url: /lehre/statistik-i/gruppenvergleiche-abhaengig-uebungen
output:
  html_document:
    keep_md: yes
private: 'true'
---

```{r setup, cache = FALSE, include = FALSE, purl = FALSE}
if (exists("figure_path")) {
  knitr::opts_chunk$set(fig.path = figure_path)
}
# Aktuell sollen die global options für die Kompilierung auf den default Einstellungen gelassen werden
```

## Vorbereitung

> Laden Sie zunächst den Datensatz `fb25` von der pandar-Website. Alternativ können Sie die fertige R-Daten-Datei [<i class="fas fa-download"></i> hier herunterladen](/daten/fb25.rda). Beachten Sie in jedem Fall, dass die [Ergänzungen im Datensatz](/lehre/statistik-i/gruppenvergleiche-abhaengig/#prep) vorausgesetzt werden. Die Bedeutung der einzelnen Variablen und ihre Antwortkategorien können Sie dem Dokument [Variablenübersicht](/lehre/statistik-i/variablen.pdf) entnehmen.

**Datenaufbereitung**

```{r, echo = F}
#### Was bisher geschah: ----

# Daten laden
load(url('https://pandar.netlify.app/daten/fb25.rda'))

# Nominalskalierte Variablen in Faktoren verwandeln
fb25$hand_factor <- factor(fb25$hand,
                             levels = 1:2,
                             labels = c("links", "rechts"))
fb25$fach <- factor(fb25$fach,
                    levels = 1:5,
                    labels = c('Allgemeine', 'Biologische', 'Entwicklung', 'Klinische', 'Diag./Meth.'))
fb25$ziel <- factor(fb25$ziel,
                        levels = 1:4,
                        labels = c("Wirtschaft", "Therapie", "Forschung", "Andere"))
fb25$wohnen <- factor(fb25$wohnen, 
                      levels = 1:4, 
                      labels = c("WG", "bei Eltern", "alleine", "sonstiges"))
fb25$fach_klin <- factor(as.numeric(fb25$fach == "Klinische"),
                         levels = 0:1,
                         labels = c("nicht klinisch", "klinisch"))

fb25$ort <- factor(fb25$ort, levels=c(1,2), labels=c("FFM", "anderer"))
fb25$job <- factor(fb25$job, levels=c(1,2), labels=c("nein", "ja"))


# Rekodierung invertierter Items
fb25$mdbf4_r <- -1 * (fb25$mdbf4 - 4 - 1)
fb25$mdbf11_r <- -1 * (fb25$mdbf11 - 4 - 1)
fb25$mdbf3_r <-  -1 * (fb25$mdbf3 - 4 - 1)
fb25$mdbf9_r <-  -1 * (fb25$mdbf9 - 4 - 1)
fb25$mdbf5_r <- -1 * (fb25$mdbf5 - 4 - 1)
fb25$mdbf7_r <- -1 * (fb25$mdbf7 - 4 - 1)

# Berechnung von Skalenwerten
fb25$wm_pre  <- fb25[, c('mdbf1', 'mdbf5_r', 
                        'mdbf7_r', 'mdbf10')] |> rowMeans()
fb25$gs_pre  <- fb25[, c('mdbf1', 'mdbf4_r', 
                        'mdbf8', 'mdbf11_r')] |> rowMeans()
fb25$ru_pre <-  fb25[, c("mdbf3_r", "mdbf6", 
                         "mdbf9_r", "mdbf12")] |> rowMeans()

# z-Standardisierung
fb25$ru_pre_zstd <- scale(fb25$ru_pre, center = TRUE, scale = TRUE)

```


## Aufgabe 1
Zu Beginn und nach der ersten Pratikumssitzung wurden Sie als Studierende nach Ihrem Befinden zum Zeitpunkt der Umfrage befragt. Hierbei wurde unteranderem erhoben, wie wach (hohe Werte) oder müde (niedrige Werte) Sie sich zu beiden Zeitpunkten gefühlt haben (Variable `wm_pre` und `wm_post`). Nun wollen Sie untersuchen, ob die Teilnahme am Statistikpraktikum einen Einfluss auf das Befinden der Studierenden hat. Sie gehen davon aus, dass sich die Angaben zu Wach vor und nach dem Praktikum unterscheidet ohne eine Richtung anzunehmen.



* Stellen Sie zunächst das Hypothesenpaar der Testung inhaltich und auch mathematisch auf. Spezifizieren Sie das Signifikanzniveau. Dieses soll so gewählt werden, dass wir die Nullhypothese in 1 von 20 Fällen fälschlicherweise verwerfen würden.

<details><summary>Lösung</summary>

**Hypothesen**

* Art des Effekts: Unterschiedshypothese  
* Richtung des Effekts: ungerichtete Hypothese
* Größe des Effekts: Unspezifisch  


Hypothesenpaar (inhaltlich):  
H0: Die Teilnahme am Statistikpraktikum wirkt sich nicht auf das Wachempfinden der Studierenden aus.
H1: Die Teilnahme am Statistikpraktikum wirkt sich auf das Wachempfinden der Studierenden aus.

Hypothesenpaar (statistisch):  

* $H_0$: $\eta_\text{nachher} = \eta_\text{vorher}$  bzw. $\mu_{d} = 0$
* $H_1$: $\eta_\text{nachher} \neq  \eta_\text{vorher}$  bzw. $\mu_{d} \neq 0$

**Spezifikation des Signifikanzniveaus**

$\alpha = .05$

</details>

* Bestimmen Sie die deskriptivstatistischen Maße und bewerten Sie diese im Hinblick auf die Hypothesen. Beachten Sie, dass bei der späteren inferenzstatistischen Testung nur Personen eingehen, die zu beiden Messzeitpunkten Angaben gemacht haben. Schließen Sie also Personen mit fehlenden Werten auf einer (oder beiden) Variablen vor der Berechnung der deskriptivstatistischen Maße aus.

<details><summary>Lösung</summary>

**Bevor es weiter geht:**

Ein Blick in den `fb25`-Datensatz verrät, dass auf dem Skalenwert `wm_post`, der Messung des Wachempfindens zum zweiten Zeitpunkt, Werte fehlen. Diese fehlenden Werte werden als *NA* abgebildet.

Um verfälschte deskriptiv- und inferenzstatistische Ergebnisse zu vermeiden, werden alle Personen aus der weiteren Berechung ausgeschlossen, die einen fehlenden Wert auf `wm_post` (oder `wm_pre`) aufweisen. Damit wir den Datensatz `fb25` aber nicht generell verändern, legen wir estmal einen neuen Datesatz an, der nur die beiden interessierenden Variablen enthält.

```{r}

wach <- fb25[, c("wm_pre", "wm_post")] #Erstellung eines neuen Datensatzes, welcher nur die für uns wichtigen Variablen enthält

wach <- na.omit(wach) #Entfernt alle Beobachtungen, die auf einer der beiden Variable einen fehlenden Wert haben

str(wach) #Ablesen der finalen Stichprobengröße
```

Nach dem Entfernen der fehlenden Werte haben wir eine Stichprobengröße von $n = 147$.

**Deskriptivstatistische Überprüfung der Hypothesen: grafisch**

Histogramme (weil die Skalenwerte Intervallskalenqualität haben):
Je ein Histogramm pro Gruppe, untereinander dargestellt, vertikale Linie für den jeweiligen Mittelwert.

```{r}
par(mfrow=c(2,1), mar=c(3,2,2,0)) # Zusammenfügen der zwei Histogramme in eine Plot-Datei und ändern der Ränder (margins) des Plot-Fensters

hist(wach[, "wm_pre"], xlim=c(0,5), ylim=c(1,50), main="Wachempfinden vor der Sitzung", xlab="", ylab="", las=1)
abline(v=mean(wach[, "wm_pre"]), lty=2, lwd=2)

hist(wach[, "wm_post"], xlim=c(0,5), ylim=c(1,50), main="Wachempfinden nach der Sitzung", xlab="", ylab="", las=1)
abline(v=mean(wach[, "wm_post"]), lty=2, lwd=2)

par(mfrow=c(1,1)) #Zurücksetzen auf default
```


**Deskriptivstatistische Beantwortung der Fragestellung: statistisch**

```{r}
summary(wach[, "wm_pre"])
summary(wach[, "wm_post"])
# aus dem Paket psych, das wir bereits installiert haben
library(psych)
describe(wach[, "wm_pre"])
describe(wach[, "wm_post"])
```
```{r, echo=FALSE}
vorher <- describe(wach[, "wm_pre"])
nachher <- describe(wach[, "wm_post"])
```
Der Mittelwert vorher ($M$ = `r round(vorher$mean, 2)`, $SD$ = `r round(vorher$sd, 2)`) ist deskriptiv höher als Mittelwert nachher ($M$ = `r round(nachher$mean, 2)`, $SD$ = `r round(nachher$sd, 2)`).

Die deskriptivstatistischen Maße unterscheiden sich. 

</details>

* Welcher inferenzstatistische Test ist zur Überprüfung der Hypothesen am geeignetsten? Prüfen Sie die Voraussetzungen dieses Tests.

<details><summary>Lösung</summary>

**Voraussetzungen für t-Test für abhängige Stichproben**

1. Die abhängige Variable ist intervallskaliert $\rightarrow$ ok

2. Die Messwerte innerhalb der Paare dürfen sich gegenseitig beeinflussen/voneinander abhängig sein; keine Abhängigkeiten zwischen den Messwertpaaren $\rightarrow$ ok

3. Die Stichprobenkennwerteverteilung der mittleren Mittelwertsdifferenz muss in der Population normalverteilt sein (ist gegeben, wenn die Verteilung der Mittelwertsdifferenzen in der Stichprobe normalverteilt ist) $\rightarrow$ ab $n > 30$ ist Normalverteilung der Stichprobenkennwerteverteilung durch zetralen Grenzwertsatz gegeben, ansonsten grafische Prüfung oder Hintergrundwissen $\rightarrow$ mit $n = 147$ erfüllt; Überprüfung der Normalverteilung von _d_ wird hier aus Übungszwecken trotzdem mit aufgeführt.

**Grafische Voraussetzungsprüfung: Normalverteilung von _d_**
```{r}
par(mar=c(3,3,3,0)) #ändern der Ränder (margins) des Plot-Fensters
difference <- wach[, "wm_pre"]-wach[, "wm_post"]
hist(difference, xlim=c(-4,4), main="Verteilung der Differenzen", xlab="Differenzen", ylab="", las=1,freq=F)
curve(dnorm(x, mean=mean(difference), sd=sd(difference)), col="blue", lwd=2, add=T)
par(mfrow=c(1,1)) #Zurücksetzen auf default
qqnorm(difference,las=1)
qqline(difference, col="blue")
```

$\Rightarrow$ Differenzen weisen leichte Abweichungen zur Normalverteilung auf. Symmetrie trotzdem gegeben und auf Grund des zentralen Grenzwertsatzes und der Stichprobengröße $\Rightarrow$ Durchführung des t-Tests für abhängige Stichproben
</details>

* Führen Sie die inferenzstatistische Testung durch.

<details><summary>Lösung</summary>

**Durchführung des _t_-Tests für abhängige Stichproben in R**

```{r}
t.test(x = wach[, "wm_pre"], y  = wach[, "wm_post"], # die Werte vorher und nachher
       paired = T,                                   # Stichproben sind abhängig
       alternative = "two.sided",                    # unggerichtete Hypothese -> zweiseitig Testung
       conf.level = .95)                             # alpha = .05
```

```{r, eval = FALSE}
# Alternative Schreibweise
t.test(x = wach$wm_pre, y = wach$wm_post, 
       paired = T,
       alternative = "two.sided",
       conf.level = .95)
```

```{r, echo=FALSE}
ttest <- t.test(x = wach[, "wm_pre"], y  = wach[, "wm_post"], paired = T, alternative = "two.sided", conf.level = .95)
```

* Zur Erinnerung: $df$ bei $t$-test mit abhängigen Stichproben: $n - 1$ (wobei $n$ die Anzahl der Paare darstellt)
* _t_(`r ttest$parameter`) = `r round(ttest$statistic, 3)`, $p $ `r if (round(ttest$p.value, 5) == 0) "<0.001" else paste0("= ", round(ttest$p.value, 5))` $\rightarrow$ ist signifikant, H0 wird verworfen.

</details>

* Bestimmen Sie unabhängig von der Signifikanzentscheidung die zugehörige Effektstärke.

<details><summary>Lösung</summary>

**Schätzung des standardisierten Populationseffekts**

```{r}
mean_d <- mean(difference) # Mittelwert der Differenzen
sd.d.est <- sd(difference) # geschätzte Populationsstandardabweichung der Differenzen
d <- mean_d/sd.d.est
d
```

$\Rightarrow$ Der standardisierte Populationseffekt beträgt _d2''_ = `r round(d, 2)` und ist laut Konventionen nach Cohen (1988) ein mittlerer Effekt. 

Zur Berechnung der Differenzvariable wurden von den Prä-Messungen die Post-Messungen abgezogen. Ein positives Vorzeichen des standardisierten Populationseffektes deutet also, wie auch unsere deskriptivstatistischen Ergebnisse, darauf hin, dass die Teilnahme am Statistikpraktikum einen negativen Effekt auf das Wachempfinden haben könnte. Dies könnte man in einer weiteren Studie inferenzstatistisch überprüfen.

</details>

* Berichten Sie die Ergebnisse formal (in schriftlicher Form).

<details><summary>Lösung</summary>

**Formales Berichten des Ergebnisses**

Es wurde in einer Wiederholungsmessung untersucht, ob sich die Teilnahme am Statistikpraktikum  auf das Wachempfinden auswirkt. Zunächst findet sich deskriptiv folgender Unterschied: Vor der Praktikumssitzung liegt der durchschnittliche Zufriedenheitswert bei `r round(vorher$mean, 2)` (_SD_ = `r round(vorher$sd, 2)`), während er nach der Praktikumssitzung bei `r round(nachher$mean, 2)` (_SD_ = `r round(nachher$sd, 2)`) liegt. 

Zur Beantwortung der Fragestellung wurde ein ungerichteter $t$-Test für abhängige Stichproben durchgeführt. Der Gruppenunterschied ist signifikant ($t$(`r ttest$parameter`) = `r round(ttest$statistic, 3)`, $p =$ `r round(ttest$p.value,3)`), somit wird die Nullhypothese verworfen und wir gehen davon aus, dass sich die Teilnahme am Statistikpraktikum die Wachheit verändert.

Der standardisierte Populationseffekt von _d''_ = `r round(d, 2)` ist laut Konventionen nach Cohen (1988) mittelgroß.

</details>
