---
title: "Tests für abhängige Stichproben" 
type: post
date: '2022-12-06' 
slug: gruppenvergleiche-abhaengig 
categories: ["Statistik I"] 
tags: ["Abhängige Stichproben", "t-Test", "Wilcoxon-Test", "Voraussetzungsprüfung"] 
subtitle: ''
summary: 'In diesem Beitrag werden abhängige Stichproben beleuchtet. Dabei geht es um vor allem um die Durchführung des abhängigen t-Tests und des abhängigen Wilcoxon-Tests.' 
authors: [nehler, koehler, buchholz, irmer, liu] 
weight: 7
lastmod: '`r Sys.Date()`'
featured: no
banner:
  image: "/header/consent_checkbox.jpg"
  caption: "[Courtesy of pxhere](https://pxhere.com/en/photo/449195)"
projects: []
reading_time: false
share: false

links:
  - icon_pack: fas
    icon: book
    name: Inhalte
    url: /lehre/statistik-i/gruppenvergleiche-abhaengig
  - icon_pack: fas
    icon: terminal
    name: Code
    url: /lehre/statistik-i/gruppenvergleiche-abhaengig.R
  - icon_pack: fas
    icon: pen-to-square
    name: Aufgaben
    url: /lehre/statistik-i/gruppenvergleiche-abhaengig-aufgaben
output:
  html_document:
    keep_md: true
---


```{r setup, cache = FALSE, include = FALSE, purl = FALSE}
# Aktuell sollen die global options für die Kompilierung auf den default Einstellungen gelassen werden
```


     
{{< spoiler text="Kernfragen der Lehreinheiten über Gruppenvergleiche" >}}
* Wie fertige ich [Deskriptivstatistiken](#Statistiken) (Grafiken, Kennwerte) zur Veranschaulichung des Unterschieds zwischen zwei Gruppen an?  
* Was sind [Voraussetzungen](#Vorraussetzungen) des abhängigen *t*-Tests und wie prüfe ich sie?
* Wie führe ich einen [abhängigen *t*-Test](#t-Test) in R durch?
* Wie berechne ich den [standardisierten Populationseffekt](#Populationseffekt) für abhängige Stichproben?  
* Wie führe ich einen [abhängigen Wilcoxon-Test](#Wilcox) in R durch?
* Wie [berichte](#Bericht) ich statistische Ergebnisse formal? 
{{< /spoiler >}}

***

## Vorbereitende Schritte {#prep}

Den Datensatz haben wir bereits über diesen [<i class="fas fa-download"></i> Link heruntergeladen](/daten/fb23.rda) und können ihn über den lokalen Speicherort einladen oder Sie können Ihn direkt mittels des folgenden Befehls aus dem Internet in das Environment bekommen. In den vorherigen Tutorials und den dazugehörigen Aufgaben haben wir bereits Änderungen am Datensatz durchgeführt, die hier nochmal aufgeführt sind, um den Datensatz auf dem aktuellen Stand zu haben:

```{r}
#### Was bisher geschah: ----

# Daten laden
load(url('https://pandar.netlify.app/daten/fb23.rda'))

# Nominalskalierte Variablen in Faktoren verwandeln
fb23$hand_factor <- factor(fb23$hand,
                             levels = 1:2,
                             labels = c("links", "rechts"))
fb23$fach <- factor(fb23$fach,
                    levels = 1:5,
                    labels = c('Allgemeine', 'Biologische', 'Entwicklung', 'Klinische', 'Diag./Meth.'))
fb23$ziel <- factor(fb23$ziel,
                        levels = 1:4,
                        labels = c("Wirtschaft", "Therapie", "Forschung", "Andere"))
fb23$wohnen <- factor(fb23$wohnen, 
                      levels = 1:4, 
                      labels = c("WG", "bei Eltern", "alleine", "sonstiges"))
fb23$fach_klin <- factor(as.numeric(fb23$fach == "Klinische"),
                         levels = 0:1,
                         labels = c("nicht klinisch", "klinisch"))
fb23$ort <- factor(fb23$ort, levels=c(1,2), labels=c("FFM", "anderer"))
fb23$job <- factor(fb23$job, levels=c(1,2), labels=c("nein", "ja"))
fb23$unipartys <- factor(fb23$uni3,
                             levels = 0:1,
                             labels = c("nein", "ja"))

# Rekodierung invertierter Items
fb23$mdbf4_pre_r <- -1 * (fb23$mdbf4_pre - 4 - 1)
fb23$mdbf11_pre_r <- -1 * (fb23$mdbf11_pre - 4 - 1)
fb23$mdbf3_pre_r <-  -1 * (fb23$mdbf3_pre - 4 - 1)
fb23$mdbf9_pre_r <-  -1 * (fb23$mdbf9_pre - 4 - 1)
fb23$mdbf5_pre_r <- -1 * (fb23$mdbf5_pre - 4 - 1)
fb23$mdbf7_pre_r <- -1 * (fb23$mdbf7_pre - 4 - 1)

# Berechnung von Skalenwerten
fb23$wm_pre  <- fb23[, c('mdbf1_pre', 'mdbf5_pre_r', 
                        'mdbf7_pre_r', 'mdbf10_pre')] |> rowMeans()
fb23$gs_pre  <- fb23[, c('mdbf1_pre', 'mdbf4_pre_r', 
                        'mdbf8_pre', 'mdbf11_pre_r')] |> rowMeans()
fb23$ru_pre <-  fb23[, c("mdbf3_pre_r", "mdbf6_pre", 
                         "mdbf9_pre_r", "mdbf12_pre")] |> rowMeans()

# z-Standardisierung
fb23$ru_pre_zstd <- scale(fb23$ru_pre, center = TRUE, scale = TRUE)

```

***

Nachdem wir uns mit **unabhängige Stichproben** in der ([letzten Sitzung](/lehre/statistik-i/gruppenvergleiche-unabhaengig)) beschäftigt haben wollen wir diesmal mit abhängigen Stichproben beschäftigen. Anwendungen dafür in der Praxis sind beispielsweise Zwillinge, Paare oder auch Messwiederholungen. Da wir nicht Ihre Geschwister mit erhoben haben, müssen wir uns in den Beispielen auf Messwiederholungen beschränken. Dafür wurden Sie einige Fragen zu Beginn und am Ende der ersten Praktikumssitzung untersucht.

***

## Mittelwertvergleich für abhängige Stichproben

Für den ersten Teil des Tutorials beschäftigen wir uns mit folgender Fragestellung: Gibt es einen Unterschied in den Werten der Subskalen 'Ruhig vs. Unruhig Stimmung' bei Psychologiestudierenden vor und nach der ersten Sitzung des Kurses? Wir nehmen in der Fragestellung keine Richtung vor, da wir für Unterschiede in beide Richtungen und Erklärungen vorstellen können. Ist nach dem Praktikum die Stimmung ruhiger, weil die Aufregung von der ersten Veranstaltung verflogen ist? Oder ist die Stimmung unruhiger, weil der erste Kontakt mit R stattgefunden hat?

Die Werte dieser Variablen zum zweiten Messzeitpunkt sind insofern voneinander abhängig, als dass jede Person dieselben Fragen zweimal beantwortet hat (Messwiederholung). Es gibt daher Faktoren innerhalb der Person, die einen gemeinsamen Teil der Varianz erzeugen. 

### Deskriptivstatistik

Wie immer beginnen wir mit der deskriptivstatistischen Analyse unserer Daten. Die beiden Variablen können wir bspw. mit dem `summary()`-Befehl näher betrachten.

```{r}
summary(fb23$ru_pre)
summary(fb23$ru_post)

```

Zunächst einmal ist offensichtlich, dass sich die Mittelwerte vor und nach der Sitzung unterscheiden. Die Frage bleibt aber bestehen, ob sich dieser Unterschied auf die Population verallgemeinern lässt. Weiterhin sticht hier direkt ins Auge, dass es nach in der Post-Variable fehlende Werte (`r sum(is.na(fb23$ru_post))`) gibt. Diese Personen können in die abhängige Testung nicht einbezogen werden und wir müssen das bei den folgenden Befehlen beachten.


Mithilfe von Histogrammen stellen wir jeweils die Verteilungen der Werte vor und nach der Sitzung dar, wobei in den Histogrammen eine vertikale Linie ergänzt ist, die den jeweiligen Mittelwert anzeigt.

```{r}
# Je ein Histogramm pro Werte, untereinander dargestellt, vertikale Linie für den jeweiligen Mittelwert
par(mfrow=c(2,1), mar=c(3,3,2,0))
hist(fb23$ru_pre, 
     xlim=c(1,5),
     ylim = c(0,80),
     main="Subskalen 'Ruhig vs. Unruhig' vor der Sitzung", 
     xlab="", 
     ylab="", 
     las=1)
abline(v=mean(fb23$ru_pre, na.rm = T), 
       lwd=3,
       col="aquamarine3")

hist(fb23$ru_post, 
     xlim=c(1,5),
     ylim = c(0,80),
     main="Subskalen 'Ruhig vs. Unruhig' nach der Sitzung", 
     xlab="", 
     ylab="", 
     las=1)
abline(v=mean(fb23$ru_post, na.rm = T), 
       lwd=3,
       col="darksalmon")
par(mfrow=c(1,1)) #Zurücksetzen des Plotfensters, zuvor hatten wir "dev.off()" kennengelernt
```

Die Funktion `abline()` fügt diese zusätzliche Linie in die Grafik ein. Mit dem Zusatzargument `v` geben wir an, dass es sich um eine vertikale Linie handeln soll. Der Ort der vertikalen Linie wird auch direkt über das Argumen `v` gesteuert. In dem Code soll diese jeweils den Mittelwert der beiden Gruppen kennzeichnen. Insgesamt scheinen sich die beiden Verteilungen  zu unterscheiden: Der Mittelwert von nach der Sitzung liegt höher als der vor der Sitzung. Beachten Sie jedoch, dass hier Personen mit fehlenden Werten auf der Post-Variable noch nicht ausgeschlossen sind, wodurch die späteren Ergebnisse anders ausfallen könnten.


### Voraussetzungsprüfung {#Vorraussetzungen}

Um unsere inferenzstistische Entscheidung mittels der $t$-Verteilung abzusichern, die beim $t$-Test passieren würde, müssen wir dessen Voraussetzungen erfüllt sein: 

**Voraussetzungen für die Durchführung des *t*-Tests für abhängige Stichproben:**  

1. Die abhängige Variable ist intervallskaliert $\rightarrow$ ok  
2. Die Messwerte innerhalb der Paare dürfen sich gegenseitig beeinflussen/voneinander abhängig sein; keine Abhängigkeiten zwischen den Messwertpaaren $\rightarrow$ ok  
3. Die Differenzvariable $d$ muss in der Population normalverteilt sein $\rightarrow$ ggf. optische Prüfung

Wir müssen also nur die Voraussetzung der Normalverteilung der Differenzvariable $d$ zusätzlich prüfen. Es ist wie bei den unabhängigen Tests üblich, diese Annahme optisch basierend auf der Stichprobe zu testen. Da wir hier die Differenzvariable betrachten wollen, müssen wir diese zunächst erstellen. Dies geht zum Glück sehr einfach, indem wir die Werte aller Personen auf `ru_pre` jeweils von ihren `ru_post` Werten abziehen. Personen mit einem fehlenden Wert auf einer der beien Variable erhalten auf `difference` jetzt automatisch ein `NA`. Somit sind alle Werte in den Grafiken die, die dann auch in unsere inferenzstatistische Prüfung eingehen. Anschließend schauen wir uns das Histogramm der Differenzvariable und den QQ-Plot an:

```{r}
difference <- fb23$ru_post-fb23$ru_pre
hist(difference, 
     xlim=c(-3,3), 
     ylim = c(0,1),
     main="Verteilung der Differenzen", 
     xlab="Differenzen", 
     ylab="", 
     las=1, 
     freq = F)
curve(dnorm(x, mean=mean(difference, na.rm = T), sd=sd(difference, na.rm = T)), 
      col="blue", 
      lwd=2, 
      add=T)
qqnorm(difference)
qqline(difference, col="blue")
```

Auf den Abbildungen sind kleine Abweichungen der Differenzen von der Normalverteilung zu sehen. Bei diesen geringen Abweichungen könnte man die Normalverteilung annehmen. Zusätzlich gilt (wie auch bei den Einstichproben- und unabhängigen Tests) der zentrale Grenzwertsatz. In Fällen, in denen die Stichprobe (also Anzahl an Messwertpaaren) ausreichend groß ist, folgt die Stichprobenkennwerteverteilung wegen auch unabhängig von der Verteilung der Differenzen in der Population der $t$-Verteilung. “Ausreichend groß” ist natürlich Auslegungssache, aber nochmal zur Erinnerung: Bei Stichproben ab $n \geq 30$ greift der Effekt, wenn das Merkmal zumindest symmetrisch verteilt ist. Andere Empfehlungen gehen besonders bei sehr schiefen Verteilungen in Richtung von 80 Messwertpaaren. Die kleinen Abweichungen von der Normalverteilung und die große Stichproben sprechen also dafür, dass unsere Stichprobenkennwerteverteilung der mittleren Differenz der $t$-Verteilung folgt. Wir können also mit der inferenzstatistischen Überprüfung starten.

### Durchführung des $t$-Test für abhängige Stichproben

Aus der Fragestellung lässt sich ableiten, dass es sich bei unserer Untersuchung um eine Unterschiedshypothese handelt, in der wir keine Richtung angenommen haben. Beginnen wir also damit, das Hypothesenpaar auszuarbeiten.

* $H_0$: Studierende sind vor und nach dem Praktikum gleich ruhig.
* $H_1$: Studierende sind vor und nach dem Praktikum unterschiedlich ruhig.

Etwas formaler ausgedrückt:

* $H_0$: $\mu_\text{vor} = \mu_\text{nach}$  bzw.  $\mu_{d} = 0$  
* $H_1$: $\mu_\text{vor} \ne \mu_\text{nach}$    bzw.  $\mu_{d} \ne 0$


Bevor wir jetzt die Rechnungen durchführen, sollten wir noch das Signifikanzniveau Untersuchung festlegen. Es soll hier 5% betragen. $\rightarrow$ $\alpha=.05$

{{<intext_anchor t-Test>}}

Wir verwenden hier die Funktion `t.test()`. Diesmal müssen wir allerdings die beiden Variablen einzeln der Funktion übergeben. Dies geschieht über die Argumente `x` und `y`. Das Argument `paired = T` führt dazu, dass der *t*-Test für abhängige (gepaarte) Stichproben durchgeführt wird.

```{r}
t.test(x = fb23$ru_post, y = fb23$ru_pre, # die beiden abhaengigen Variablen
      paired = T,                      # Stichproben sind abhaengig
      conf.level = .95)   

```

```{r, echo=FALSE}
ttest <- t.test(x = fb23$ru_post, y = fb23$ru_pre,
       paired = T, conf.level = .95)
```

Auf den ursprünglichen Variablen sind immer noch die Personen mit fehlenden Werten enthalten. Trotzdem meldet die Funktion `t.test()` kein Problem. Was passiert hier also? Ein Indiz können uns die Freiheitsgrade beiten, die mit $n-1$ bestimmt werden können. Hier wird deutlich, dass Personen mit fehlenden Werten auf einer der beiden Variablen einfach ignoriert werden. Aber man bekommt (außer der überraschend kleinen Freiheitsgraden im Vergleich zur Größer des Datensatzes keine) keine Warnungn dazu. Kommen wir zur Interpretation des Ergebnis. $t$(`r ttest$parameter`) = `r round(ttest$statistic, 2)` -- der zugehörige p-Wert ($p < .01$) ist somit kleiner als unser festelegtes $\alpha$. Wir verwerfen die $H_0$ und nehmen die $H_1$ an.



### Schätzung des standardisierten Populationseffekts {#Populationseffekt}

Formel: $$\text{Cohen's } d'' = \frac{\bar{d}} {\hat{sd}_{d}}$$
wobei  

* $\bar{d}$: Mittelwert der Differenz aller Wertepaare  
* $\hat{sd}_{d}$: geschätzte SD der Differenzen  

Wir führen die Berechnung von Cohen's $d$ für abhängige Stichproben zunächst von Hand durch. Dafür speichern wir uns die nötigen Größen ab und wenden dann die präsentierte Formel an:

```{r}
mean_d <- mean(difference, na.rm = T)
sd.d.est <- sd(difference, na.rm = T)
d_Wert <- mean_d/sd.d.est
d_Wert
```

**Berechnung mit Funktion `cohen.d()`**
```{r, results="hide"}
#alternativ:
#install.packages("effsize")
library("effsize")
```

```{r}
d2 <- cohen.d(fb23$ru_post, fb23$ru_pre, 
      paired = TRUE,  #paired steht fuer 'abhaengig'
      within = FALSE, #wir brauchen nicht die Varianz innerhalb
      na.rm = TRUE)   
d2
```

Mit dem Argument `within = T`, was der Default ist, wird für die Varianzberechnung die Varianz innerhalb der Gruppen herangezogen (vergleiche Formel Cohen's $d$ für unanghängige Stichproben).

Wie auch zu den vorherigen inferenzstatistischen Tests gibt es auch hier Konventionen nach Cohen (1988). Die Werte unterscheiden sich zwischen abhängigem und unabhängigem $t$-Test. Wir möchten aber nochmal betonen, dass diese Konventionen nur bei völliger Ahnungslosigkeit genutzt werden sollten und sonst Effekstärken im Rahmen des Anwendungsgebietes eingeordnet werden sollten.

_d''_ | Interpretation |
:-: | :------: |
~ .14 | kleiner Effekt |
~ .35 | mittlerer Effekt |
~ .57 | großer Effekt |

Zusammenfassend lässt sich sagen: Der standardisierte Populationseffekt beträgt $d_2''$ = `r round(d_Wert, 2)` und ist laut Konventionen klein bis mittel. 


### Ergebnisinterpretation
Zunächst findet sich deskriptiv ein Unterschied: 
Der Mittelwert der Differenzen zwischen ruhig und unruhig beträgt `r round(mean(difference, na.rm = T), 2)`. Zur Beantwortung der Fragestellung wurde ein ungerichteter $t$-Test für abhängige Stichproben durchgeführt. Der Unterschied zwischen den beiden Messzeitpunkten ist signifikant ($t$(`r ttest$parameter`) = `r round(ttest$statistic, 2)`, $p < .01$), somit wird die Nullhypothese verworfen. Dieser Unterschied ist nach dem standardisierten Populationseffekt von $d_2''$ = `r round(d_Wert, 2)` klein bis mittel.

***


## Medianvergleich für abhängige Stichprobe

Fragestellung: Erreichen die Studierenden in ihrer 'Guten vs. Schlechten Stimmung' nach der ersten Sitzung im Mittel höhere Werte als vor der ersten Sitzung des Kurses?

Wie bei der letzten Forschungsfrage hat jede Person die gleichen Fragen zweimal beantwortet (Messwiederholung), so dass die Werte dieser Variablen zum zweiten Messzeitpunkt voneinander abhängig sind. Der Unterschied besteht jedoch darin, dass diese Hypothese gerichtet ist. 

Allerdings konzentrieren wir uns nicht auf den Vergleich von Mittelwerten, sondern auf den von Medianen. Der Grund dafür liegt in der theoretischen Überlegung, dass der Mittelwert in diesem Kontext kein adäquater Repräsentant für die Variable ist. Es kann sein, dass der Mittelwert durch Ausreißer verzerrt wird, während der Median ein robusteres Maß darstellt, das den zentralen Trend der Daten besser widerspiegelt. 


### Deskriptivstatistik

Wie immer beginnen wir mit der deskriptivstatistischen Analyse unserer Daten. Im letzten Abschnitt haben wir bereits gesehen, dass es bei der Post-Befragung eine größere Zahl an fehlenden Werten gab. 

```{r}
summary(fb23$gs_pre)
summary(fb23$gs_post)
```

Es zeigt sich, dass es sowohl in der Pre- als auch in der Post-Befragung fehlende Werte gibt. Damit alle folgenden Ergebnisse auf den gleichen Daten basieren, reduzieren wir unseren Datensatz auf Personen, die zu beiden Zeitpunkten Antworten gegeben haben und legen diesen neuen Datensatz unter dem Namen `gut` ab. Gleichzeitig sollen dort auch nur noch die beiden Variablen von Interesse beinhaltet sein.

```{r}
gut <- fb23[, c("gs_pre", "gs_post")] # Erstellung eines neuen Datensatzes, welcher nur die für uns wichtigen Variablen enthält

gut <- na.omit(gut) # Entfernt alle Beobachtungen, die auf einer der beiden Variable einen fehlenden Wert haben

nrow(gut) # resultierende Stichprobengröße

```



Lassen wir uns die Subskala nun grafisch ausgeben, wofür beim Vergleich der Mediane ein Boxplot gut geeignet ist.

```{r}
# Je ein Histogramm pro Gruppe, untereinander dargestellt, vertikale Linie für den jeweiligen Mittelwert
par(mfrow=c(1,2), mar=c(3,3,2,0))
boxplot(fb23$gs_pre, 
     main="Subskala Gut vor der Sitzung", 
     las=1)


boxplot(fb23$gs_post, 
     main="Subskala Schlecht nach der Sitzung", 
     las=1)

par(mfrow=c(1,1)) #Zurücksetzen des Plotfensters
```

Hier sieht man direkt, dass es viele Ausreißer in beiden Messperioden gibt. Dies ist der Grund, warum der Median ein geeignetes Maß für die zentrale Tendenz ist. Leider ist der Median vor und nach dem Praktikum genau gleich. Damit würde sich eigentlich die weitere Untersuchung erübrigen. Zu Übungszwecken werden wir sie trotzdem durchführen.



### Voraussetzungsprüfung

Zunächst prüfen wir, ob wir zur Beantwortung der Fragestellung einen Wilcoxon-Tests-Test für abhängige Stichproben verwenden können: 

**Voraussetzungen für die Durchführung des Wilcoxon-Tests (für abhängige Stichproben):**


1.  die Messwerte innerhalb der Paare dürfen sich gegenseitig beeinflussen/voneinander abhängig sein; keine Abhängigkeiten zwischen den Messwertpaaren $\rightarrow$ ok\
2.  die Differenzvariable ist in der Population stetig (zumindest singulär ordinal) 
3.  die Differenzvariable ist symmetrisch verteilt (nicht notwendigerweise normalverteilt; ggf. grafische Prüfung oder Hintergrundwissen)

### 5.3. Inferenzstatistik mit dem Wilcoxon-Vorzeichen-Rangtest für abhängige Stichproben

Aus unserer Fragestellung wird eine Unterschiedsyhpothese deutlich, die einen gerichteten Effekt postuliert. Das Hypothesenpaar sieht folgendermaßen aus:

* $H_0$: $\eta_\text{nach} \le \eta_\text{vor}$    
* $H_1$: $\eta_\text{nach} > \eta_\text{vor}$    

Weiterhin muss das Signifikanzniveau vor der Untersuchung festgelegt werden. Es soll hier 5% betragen. $\rightarrow$ $\alpha=.05$.

{{<intext_anchor Wilcox>}}

Die Argumente der Funktion für den Wilcoxon-Vorzeichen-Rangsummentest für abhängige Stichproben sehen dem des $t$-Tests für abhängige Stichproben sehr ähnlich. 

```{r}
wilcox.test(x = fb23$gs_post, 
            y = fb23$gs_pre, # die beiden abhängigen Gruppen
            paired = T,      # Stichproben sind abhängig
            alternative = "greater", # gerichtete Hypothese
            exact = T,
            conf.level = .95)                 # alpha = .05
```

```{r, echo=FALSE}
wilcox <- wilcox.test(x = fb23$gs_post, y  = fb23$gs_pre, paired = T, alternative = "greater", conf.level = .95)
```

V = `r wilcox$statistic`, _p_ < .05 $\rightarrow$ H0 wird verworfen.


### Ergebnisinterpretation  

Zunächst findet sich deskriptiv keine Unterschied: 
Vor und nach der ersten Sitzung weisen die Studierenden einen identischen Median von `r round(median(fb23$gs_post, na.rm = T), 2 )` (_IQR_ = `r round(abs(diff(quantile(fb23$gs_post, probs = c(.25, .75), na.rm =T))), 2)`) auf [IQR ist die Interquartil-Range also die Distanz vom Prozentrang 25% bis zum Prozentrang 75%]. Da der Mittelwert in diesem Kontext nicht adäquater Repräsentant für die Variable ist, wurde ein Wilcoxon-Test für abhängige Stichproben durchgeführt, um die Medien zu vergleichen. Der Unterschied wurde bei einem Signifikanzniveau von alpha = .05 signifikant (_V_ = `r wilcox$statistic`, _p_ < .01). Somit wird die Nullhypothese verworfen. 
