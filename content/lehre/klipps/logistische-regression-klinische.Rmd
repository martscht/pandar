---
title: Logistische Regression
date: '2024-09-26'
slug: logistische-regression-klinische
categories: ["KliPPs"]
tags: ["dichotom", "generalisiertes lineares Modell", "Linkfunktion", "Likelihood"]
subtitle: 'Vorhersage von Gruppenzugehörigkeiten'
summary: ''
authors: [schultze]
weight: 2
lastmod: '`r Sys.Date()`'
featured: no
banner:
  image: "/header/talking_beach.jpg"
  caption: "[Courtesy of pxhere](https://pxhere.com/en/photo/657502)"
projects: []

reading_time: false 
share: false

links:
  - icon_pack: fas
    icon: book
    name: Inhalte
    url: /lehre/klipps/logistische-regression-klinische
  - icon_pack: fas
    icon: terminal
    name: Code
    url: /lehre/klipps/logistische-regression-klinische.R
  - icon_pack: fas
    icon: newspaper
    name: Artikel
    url: https://doi.org/10.1016/j.jad.2023.02.148
  - icon_pack: fas
    icon: folder-open
    name: OSF
    url: https://osf.io/y7dse/
    
output:
  html_document:
    keep_md: true
---

```{r setup, cache = FALSE, include = FALSE, purl = FALSE}
if (exists("figure_path")) {
  knitr::opts_chunk$set(fig.path = figure_path)
}
# Aktuell sollen die global options für die Kompilierung auf den default Einstellungen gelassen werden
library(ggplot2) # ggplot2 und dplyr werden nur für Grafiken benötigt
source('https://pandar.netlify.app/lehre/statistik-ii/pandar_theme.R')
```

{{< toc >}}

## Einleitung

In diesem Beitrag geht es darum, wie wir die Prinzipien der [Regression](/multiple-regression-klinische) nutzen können, um Vorhersagen auch dann zu ermöglichen, wenn die abhängige Variable nominalskaliert ist. Solche Konstellationen sind insbesondere in der klinischen Forschung sehr verbreitet - die Vorhersage eines Rezidivs, einer potentiellen Diagnose oder eines Therapieerfolgs stellen allesamt häufig zentrale Fragen von Psychotherapieforschung dar.

### Suizidgedanken und -versuche

Wie in den vergangenen Beiträgen auch, werden wir versuchen, die Auswertung und Ergebnisse einer Studie aus der klinischen Forschung nachzuvollziehen. In diesem Beitrag geht es um eine Studie von [Lin, O'Connell und Law (2023)](https://doi.org/10.1016/j.jad.2023.02.148), in welcher die Autorinnen untersuchen, inwiefern Kontrollüberzeugungen und Durchhaltevermögen (Grit) die negativen Konsequenzen von Rumination auf Suizidgedanken und -versuche abschwächen oder verstärken. Da es sich bei der Studie um eine Querschnittuntersuchung handelt, werden die Wirkmechanismen hier allerdings ungerichtet untersuchte, sodass untersucht wird, inwiefern sich drei Gruppen unterscheiden: Personen, die in der Vergangenheit Suizidgedanken hatten, Personen, die in der Vergangenheit Suizidversuche unternommen haben und Personen, auf die keines von beiden zutrifft. 

Genauer konzentrieren wir uns auf folgende Hypothesen bzw. Forschungsfragen der Studie:

> Given findings from past research, we hypothesize grit to be protective against the development of suicidal ideation, but associated with facilitating suicidal behaviors in the presence of ideation.

> Further, we hypothesize ILOC [internal locus of control] to amplify the self-directed negative emotions of rumination, allowing one to believe their life outcomes are the result of self-determination, and increase risks of suicide.

> In contrast, ELOC [external locus of control] would be protective against rumination by displacing the contents of rumination externally, thereby decreasing vulnerability to suicide.

Schauen wir uns an, wie diese Hypothesen geprüft werden können. 

### Daten

Die Daten wurden von den Autorinnen der Studie über das [OSF zur Verfügung](https://osf.io/y7dse/) gestellt. Sie stellen außerdem auch eine .Rmd-Datei zur Verfügung, in der die Datenaufbereitung für den Artikel dargestellt wird. Ich habe dieses Skript ein wenig gekürzt und damit wir schnell zu den interessanten Punkten kommen können, können wir dieses Skript einfach direkt ausführen, um die Daten in R zu laden:

```{r, eval=FALSE}
source('https://pandar.netlify.app/daten/Data_Processing_grit.R')
```

```{r, echo = FALSE, purl = FALSE}
load('/home/martin/projects/klipps/datasets/grit.rda')
```
_Anmerkung: Leider wurde der Datensatz aus dem OSF entfernt, nachdem ich mit den Autorinnen des Artikels Kontakt aufgenommen habe (mehr dazu später). Die Daten erhalten Sie daher derzeit nur, wenn Sie am Kurs teilnehmen._

Der Datensatz besteht aus ein paar Skalenwerten, demografischen Variablen und der für uns entscheidenen Angabe, ob Personen schon einmal Suizidgedanken oder -versuche durchlebt haben (`Suicide`). Eine detaillierte Darstellung der Variablen findet sich im Artikel von [Lin et al. (2023)](https://doi.org/10.1016/j.jad.2023.02.148), hier nur noch ein kurzer Überblick:

<details><summary><b>Variablenübersicht</b></summary>

Variable | Beschreibung | Ausprägungen
--- | ------ | ----- 
`Suicide` | Suizidgedanken und -versuche | `None`, `Ideator`, `Attempter`
`ARS` | Anger Rumination Scale | *Skalenwert*, 0-76
`RSS` | Rumination on Sadness Scale | *Skalenwert*, 0-65
`ILOC` | Internal Locus of Control | *Skalenwert*, 0-48
`ELOC` | External Locus of Control | *Skalenwert*, 0-96
`Grit` | Grit Scale | *Skalenmittelwert*, 0-4
`Age` | Alter | in Jahren
`Sex` | Geschlecht | `Female`, `Male`, `Other`
`Employment` | Beschäftigungsverhältnis | `Unemployed`, `Part-Time`, `Full-Time`
`Marital` | Familienstand | `Never Married`, `Actively Married`, `Not Actively Married`, `Divorced`, `Widowed`
`SES` | Sozioökonomischer Status | *Einkommensbänder*
`Orientation` | Sexuelle Orientierung | `Heterosexual`, `Homosexual`, `Bisexual`, `Other/Missing`

</details>

### Stichprobenbeschreibung

Die Deskriptivstatistiken der Variablen, die für uns relevant sind, werden in Tabelle 1 des Aritkels von [Lin et al. (2023)](https://doi.org/10.1016/j.jad.2023.02.148) dargestellt. Wir können relativ einfach prüfen, ob wir diese reproduzieren können. Weil die Tabelle die Ergebnisse nach den drei Gruppen `None`, `Ideator` und `Attempter` aufteilt, können wir den `describeBy`-Befehl aus dem `psych`-Paket nutzen, um diese Unterteilung direkt mitzumachen. Weil die ausgegebenen Statistiken für nominalskalierte Variablen nicht sinnvoll sind, schließen wir diese aus dem Datensatz aus, bevor wir ihn mit der Pipe `|>` an die Funktion weitergeben.

```{r}
library(psych)
subset(grit, select = c(ARS, RSS, ELOC, ILOC, Grit, Age)) |>
  describeBy(grit$Suicide)
```

Insgesamt scheinen die Ergebnisse mit den Angaben im Artikel weitestgehend übereinzustimmen, lediglich bei der Gruppe `None` scheinen sich bei den Angaben zu den Variablen `ARS` und `RSS` Unstimmigkeiten eingeschlichen zu haben (die ich auch durche eine Nachfrage bei den Autorinnen nicht klären konnte). Die Verteilungen der nominalskalierten Variablen hingegen scheinen zu passen.


```{r, eval = FALSE}
table(grit$Suicide, grit$Sex) |> addmargins()
table(grit$Suicide, grit$Employment) |> addmargins()
table(grit$Suicide, grit$Marital) |> addmargins()
table(grit$Suicide, grit$SES) |> addmargins()
table(grit$Suicide, grit$Orientation) |> addmargins()
```

(Die Ausgabe habe ich an dieser Stelle mal ausgespart, Sie können Sie aber einfach direkt bei sich mit dem dargestellten Code ausgeben lassen.)

## Logistische Regression

In der (normalen) logistischen Regression geht es uns darum, eine dichotome abhängige Variable in einer Regression vorherzusagen. Wenn wir uns auf die erste Hypothese der Autorinnen zuückbesinnen:

> [...] we hypothesize grit to be protective against the development of suicidal ideation [...]

können wir uns also erst einmal damit befassen, Unterschiede zwischen Personen, die Suizidgedanken hatten und Personen, die weder Suizidgedanken hatten noch Suizidversuche unternommen haben zu untersuchen. Dazu erstellen wir erst einmal einen Datensatz, der nur diese Personen enhält:

```{r}
idea <- subset(grit, grit$Suicide %in% c('None', 'Ideator'))
idea$Suicide <- droplevels(idea$Suicide)
```

In diesem Datensatz sind nun nur noch `r nrow(idea)` der ursprünglichen `r nrow(grit)` Personen enthalten, weil wir nur die beiden Gruppen betrachten. Wir führen aber später, wenn wir uns die [multinomiale logistische Regression angucken](#multinomiale-logistische-regression) angucken, wieder alle Personen zusammen und betrachten die gesamte Stichprobe.

### Warum keine lineare Regression?

Bevor wir uns angucken, wie man es richtig macht, gucken wir uns zunächst an, warum die normale Regression in diesem Fall ungeeignet ist. Wie Sie vielleicht in Erinnerung haben, treffen wir in der multiplen Regression im wesentlichen fünf Annahmen (die Sie in ausuferndem Detail im Beitrag zur [Multiplen Regression](/lehre/statistik-i/multiple-reg#voraussetzungen-der-multiplen-regression) nochmal nachlesen können). Eine davon ist die Normalverteilung der Residuen - eine vielleicht etwas optimistische Annahme, angesichts der Tatsache, dass unsere AV nur zwei Ausprägungen hat, aber probieren wir es aus:

```{r Lineare Regression}
# Lineare Regression
mod0 <- lm(Suicide ~ 1 + Grit, idea)
```

Wir sehen direkt, dass R sich weigert unser unlauteres Vorhaben zu unterstützen; wir müssen die Variable also zunächst in eine numerische Variable überführen:

```{r Lineare Regression Versuch 2}
# Lineare Regression
mod0 <- lm(as.numeric(Suicide) ~ 1 + Grit, idea)

# Ergebnisübersicht
summary(mod0)
```
Das Ergebnis zeigt uns zunächst an, dass Personen mit mehr Grit weniger Suizidgedanken haben. Betrachten wir das Ganze mal als Abbildung:

```{r Abbildung-Lineare-Regression, fig = TRUE, echo = FALSE, warning=FALSE, message=FALSE}
ggplot(idea, aes(x = Grit, y = as.numeric(Suicide))) + 
  geom_point(alpha = .25) + 
  geom_smooth(method = 'lm', se = FALSE, color = pandar_colors[1]) +
  theme_pandar()
```
Wie man sieht, ist die von der Regression angenommene lineare Beziehung keine besonders gute Abbildung des wahren Zusammenhangs. Vorhergesagt werden ausschließlich Wrte, die nicht vorkommen können (weil sie weder `1` noch `2` sind). Noch deutlicher wird die Unzulänglichkeit der linearen Regression, wenn wir uns die Verteilung der Residuen angucken:

```{r Residuen-Lineare-Regression, fig = TRUE, warning=FALSE, message=FALSE}
residuals(mod0) |> hist()
```

Wie bereits erwähnt, sollten diese Residuen normalverteilt sein, damit die Inferenzstatistik des Regressionsgewichts vertrauenswürdig ist. Den `shapiro.test` erspare ich uns angesichts dieser sehr deutlichen Lage.

### Grundidee der logistischen Regression

Im Grunde ist das Problem im Fall von dichotomen abhängigen Variablen lediglich, dass Ausprägungen nicht einfach mit $Y = \widehat{Y} + e$ in zwei Teile zerlegt werden können, weil eine Annäherung des echten Wertes einer Person mit mehr oder weniger Genauigkeit etwas ungelenk scheint, wenn wir von vornherein wissen, dass die Variable nur zwei Ausprägungen haben kann. Daher wird bei der logistischen Regression die Wahrscheinlichkeit einer Kategorie (im Kontrast zu einer exklusiven anderen Kategorie) modelliert. So wird die Eigenschaft beibehalten, dass wir in der Regression Unsicherheit quantifizieren, statt im Residuum nun darüber, dass wir _Wahrscheinlichkeiten_ statt Werte modellieren. Diese Wahrscheinlichkeit ist dabei eine Funktion der unabhängigen Variablen. Der so entstandene Ansatz ist eine Generalisierung des linearen Modells (`lm`) der Regression und wird daher _generalisiertes lineares Modell_ (`glm`) genannt. 

Wenn wir wieder auf die Annahme zurückkommen, dass Grit ein protektiver Faktor gegenüber Suizidgedanken ist, heißt das, dass die Wahrscheinlichkeit, dass eine Person Suizidgedanken hatte, ein Funktion Ihrer Werte auf der `Grit` Variable sein sollte. Etwas formaler ausgedrückt, wollen wir die bedingte Wahrscheinlichkeit von $Y = 1$ (also, dass es in der Vergangenheit zu Suizidgedanken kam) gegeben $X = x$ (also, dass eine Person einen bestimmten Wert $x$ auf der `Grit` Variable $X$ hat) modellieren. Worum es uns geht, ist in welcher Form sich Unterschiede in $X$ in Unterschiede in der Wahrscheinlichkeit übersetzen.

Weil die Wahrscheinlichkeit einen beschränkten Wertebereich hat (0 bis 1), können wir auch diese nicht einfach mit der linearen Regression vorhersagen, weil die Vorhersage sonst relativ schnell den Bereich zulässiger Werte verlassen würden. Daher ist eine Funktion von nöten, die im Wertebereich ebenfalls auf $[0; 1]$ eingeschränkt ist. Eine einfache Lösung ist dafür die Exponentialfunktion nach dem Schema

$$
  \mathbb{P}(Y = 1 | X = x) = \frac{e^{\beta_0 + \beta_1x}}{1 + e^{\beta_0 + \beta_1x}}
$$
zu nutzen. Hier ist der Exponent die alte bekannte Regressionsgleichung aus $\beta_0$ und $\beta_1$. Im Seminar und bei Eid, Gollwitzer und Schmitt (2017, Kap. 22.1) wird genauer besprochen, was die einzelnen Werte in diesem Fall bedeuten und warum es eigentlich drei verschiedene Formen gibt, die logistische Regression darzustellen. In den Sozialwissenschaften wird meistens der sogenannte _Logit_ als Link-Funktion verwendet, um die Gleichung eine Form umzuwandeln, die unserer klassischen Regression entspricht:

$$
  \text{logit}(p) = \ln\left(\frac{\mathbb{P}(Y = 1 | X = x)}{1 - \mathbb{P}(Y = 1 | X = x)}\right) = \beta_0 + \beta_1x
$$
In der Regression, wie wir sie anwenden werden wird also das logarithmierte Verhältnis der Wahrscheinlichkeit einer Kategorie und der Gegenwahrscheinlichkeit (Odds) modelliert. Gucken wir uns am Besten am Beispiel an, was das genau bedeutet.

### Einfache Logistische Regression

Wie schon angedeutet, ist der Befehl den wir nutzen werden der `glm` Befehl (für _generalized linear model_). Der Funktioniert eigentlich genau so, wie der `lm`-Befehl funktioniert. Als erstes Brauchen wir die Formel, in der wir festhalten, von welchen Variablen die Wahrscheinlichkeit abhängt, dass Personen in der Vergangenheit Suizidgedanken hatten. Nach [Lin et al. (2023, S. 251)](https://doi.org/10.1016/j.jad.2023.02.148) sollte dabei `Grit` eine wesentliche Rolle spielen, da

> Some have also suggested grit to be protective of [suicidal thoughts and behaviors] (Marie et al., 2019), buffering against suicidal ideation by maintaining life goals and promoting a sense of purpose (Kleiman et al., 2013), as well as decreasing the impact of hopelessness (Pennings et al., 2015), negative life events (Blalock et al., 2015), and depression (Kim, 2015).

Als einfache logistische Regression ausgedrückt also:

```{r Einfache-Logistischte-Regression}
# Logistische Regression
mod1 <- glm(Suicide ~ 1 + Grit, data = idea, family = 'binomial')
```

Da der Oberbegriff _generalisiertes lineares Modell_ eine Vielzahl von verschiedenen Möglichkeiten umfasst, müssen wir im `glm`-Befehl mit dem Argument `family = 'binomial'` festlegen, dass unser Modell eine Binomialverteilung annimmt - unser abhängige Variable also binär bzw. dichotom ist.

Der Output dieser Prozedur sieht der einfachen Regression erstaunlich ähnlich:

```{r Summary-Einfache-Logistische-Regression}
# Ergebnisausgabe
summary(mod1)
```
Konzentrieren wir uns erstmal auf die Koeffizienten. Intercept und Regressionsgewicht sind analog zur einfachen linearen Regression interpretierbar:

  - $\beta_0$: Vorhergesagter Logit für Personen mit einem `Grit`-Wert von 0
  - $\beta_1$: Vorhergesagter Unterschied im Logit zwischen zwei Personen, die sich um eine Einheit im `Grit` unterscheiden
  
Das Problem bei dieser Interpretation ist nur, dass der Logit nicht wirklich intuitiv interpretierbar ist. Daher werden die Ergebnisse der Regression häufig in Odds umgerechnet (zur [Erinnerung an Odds und Odds-Ratios können Sie in diesem Beitrag](/lehre/statistik-i/korrelation/#odds-wettquotient-und-odds-ratio) nachgucken). Weil der Logit einfach der logarithmierte Odds ist, können wir durch exponieren auch den Odds erhalten:

```{r}
# Odds
exp(coef(mod1))
```

Bei einem `Grit`-Wert von 0 ist es also knapp `r round(exp(coef(mod1))[1], 2)`-mal so wahrscheinlich in der Vergangenheit Suizidgedanken gehabt zu haben, wie es ist, sie nicht gehabt zu haben. Wenn sich zwei Personen auf der `Grit`-Skala um eine Einheit unterscheiden, ist die Wahrscheinlichkeit der Suizidgedanken der Person mit dem höheren Wert nur ungefähr das `r round(exp(coef(mod1))[2], 2)`-fache der Person mit dem niedrigeren Wert.

Für jeden einzelnen Wert können wir außerdem die Wahrscheinlichkeit berechnen, dass Person Suizidgedanken hatten. Dafür können wir zunächst, wie bei der normalen Regression, die vorhergesagten Logits bestimmen und diese dann in Wahrscheinlichkeiten umrechnen:

```{r}
# Ganze Werte auf der Grit Skala
new_data <- data.frame(Grit = 0:4)

# Vorhersage
new_data$Logits <- predict(mod1, newdata = new_data)

# Umrechnung in Wahrscheinlichkeit
new_data$Probability <- exp(new_data$Logits) / (1 + exp(new_data$Logits))

# Ausgabe
new_data
```
Zum Glück, können wir das Ganze in `predict` auch abkürzen, wenn wir direkt die Wahrscheinlichkeiten anfordern:

```{r, eval = FALSE}
new_data$Probability <- predict(mod1, newdata = new_data, type = 'response')
```


Die Ergebnisse können wir natürlich auch bildlich veranschaulichen (den entsprechenden R-Code dazu finden Sie im oben verlinkten R-Skript für diesen Beitrag):

```{r Abbildung-Logistische-Regression, fig = TRUE, echo = FALSE, warning=FALSE, message=FALSE, height=4, width=4}
# Daten und Vorhersagen erstellen
plottable <- data.frame(Grit = seq(0, 4, .01))
plottable$Probability <- predict(mod1, newdata = plottable, type = 'response')

# GGplot erstellen
ggplot(plottable, aes(x = Grit, y = Probability)) +
  geom_line(color = pandar_colors[1]) + 
  theme_pandar() + 
  ylim(0, 1)
```
Sowohl die Ergebnisse der Regression als auch die Abbildung scheinen den Annahmen von [Lin et al. (2023)](https://doi.org/10.1016/j.jad.2023.02.148) also Recht zu geben: mehr Grit scheint mit bedeutsam weniger Suizidgedanken einherzugehen.

Von der APA wird empfohlen, für Ergebnisse der logistischen Regression Odds und deren Konfidenzintervalle zu präsentieren. Da wir schon wissen, wie wir die Regressiongewichte in Odds umrechnen, brauchen wir nur noch die Konfidenzintervalle. Die `confint`-Funktion gibt diese natürlich auch in Logits aus, aber sie sind nach dem gleichen Prinzip in Odds umrechenbar, wie die Koeffizienten selbst:

```{r Konfidenzintervalle}
# Konfidenzintervalle
ci <- confint(mod1)

# Ergebnisse
results <- data.frame(
  Odds = exp(coef(mod1)),
  Lower = exp(ci[, 1]),
  Upper = exp(ci[, 2])
)

# Ausgabe
results
```

Im Einklang mit den Ergebnissen der $p$-Werte aus der `summary` sagen uns die Konfidenzintervalle hier, dass sowohl das Intercept als auch der Regressionskoeffizient für `Grit` signifikant von 1 (gleicher Wahrscheinlichkeit) verschieden sind.

### Mehrere Prädiktoren und Modellvergleiche

Die Erweiterung der logistischen Regression auf mehrere Prädiktoren funktionier eigentlich genauso, wie bei der linearen Regression. Wenn wir Tabelle 3 in [Lin et al. (2023)](https://doi.org/10.1016/j.jad.2023.02.148) betrachten, sehen wir die Ergebnisse verschiedener Modelle, mit jeweils sequentiell aufgenommenen Blöcken von Prädiktoren. In unserem eingeschränkten `idea` Datensatz befinden sich derzeit alle Personen, die als `Ideator` oder `None` klassifiziert wurden. Wir können also versuchen, die Ergebnisse aus der zweiten Spalte des _Model 1_ zu reproduzieren. Dafür brauchen wir vier Modelle:

  - **Block 1**: Nur eine dichotomisierte `Orientation`-Variable
  - **Block 2**: Zusätzlich `ARS`, `ILOC` und `Grit`
  - **Block 3**: Zusätzlich die paarweisen Interaktionen zwischen `ARS`, `ILOC` und `Grit`
  - **Block 4**: Zusätzlich die dreifach-Interaktion zwischen `ARS`, `ILOC` und `Grit`

Die Grundideen, die wir in den letzten beiden Beiträgen hinsichtlich der [moderierten Regression](/lehre/klipps/multiple-regression-klinische) und der [generalisierten ANCOVA](/lehre/klipps/ancova-klinische) besprochen hatten halten auch hier (wir haben ja nur ausgetauscht, wie wir unsere abhängige Variable behandeln). Deswegen müssen wir auch hier die Variablen zentrieren, um nicht-essentielle Multikollinearität zu vermeiden:

```{r}
# Zentrierung
idea$ARS_c <- scale(idea$ARS, scale = FALSE)
idea$ILOC_c <- scale(idea$ILOC, scale = FALSE)
idea$Grit_c <- scale(idea$Grit, scale = FALSE)
```

Außerdem müssen wir - im Einklang mit dem Vorgehen von [Lin et al. (2023)](https://doi.org/10.1016/j.jad.2023.02.148) - die `Orientation` Variable so umkodieren, dass sie den dichotomen Kontrast zwischen heterosexuellen und nicht-heterosexuellen Personen abbildet:

```{r}
# dichotome Orientierung
idea$Orientation_bin <- factor(idea$Orientation, 
  labels = c('Hetero', 'LGBTQ', 'LGBTQ', 'LGBTQ'))
```


Stellen wir direkt alle vier Modell auf:

```{r Mehrere-Prädiktoren}
# Modelle aus Tabelle 3, Model 1, Spalte 2
block1 <- glm(Suicide ~ 1 + Orientation_bin, 
  idea, family = 'binomial')
block2 <- glm(Suicide ~ 1 + Orientation_bin + ARS_c + ILOC_c + Grit_c,
  idea, family = 'binomial')
block3 <- glm(Suicide ~ 1 + Orientation_bin + ARS_c + ILOC_c + Grit_c +
    ARS_c:ILOC_c + ARS_c:Grit_c + ILOC_c:Grit_c,
  idea, family = 'binomial')
block4 <- glm(Suicide ~ 1 + Orientation_bin + ARS_c + ILOC_c + Grit_c +
    ARS_c:ILOC_c + ARS_c:Grit_c + ILOC_c:Grit_c +
    ARS_c:ILOC_c:Grit_c,
  idea, family = 'binomial')
```

Wie in der linearen multiple Regression, macht es auch hier Sinn erst zu beurteilen, welches Modell das Beste ist, bevor wir in die Interpretation der einzelnen Ergebnisse übergehen. In der linearen Regression hatten wir Modelle anhand der Differenz der Varianzaufklärung $R^2$ bzw. Quadratsummen verglichen. Leider funktioniert beides hier nicht mehr, da es weder Varianzaufklärung noch Residualquadratsummen gibt, wenn es keine Residuen gibt. Da die logistische Regression aber mittels _Maximum-Likelihood Schätzverfahren_ geschätzt wird, können wir die Likelihood der beiden Modelle direkt miteinander vergleichen. 

Sehr vereinfacht gesagt, stellt die Likelihood jedes Modells dar, wie wahrscheinlich die beobachteten Daten sind, wenn dieses Modell das wahre Modell wäre. Für den direkten Vergleich zwischen zwei Modellen können wir uns dies zunutze machen, weil wir das Modell bevorzugen wollen, bei dem die Daten wahrscheinlicher sind, die wir beobachtet haben. Weil mehr Parameter dabei die Daten immer wahrscheinlicher machen, müssen wir darauf achten, dass das Modell in größerem Ausmaß besser wird, als wir durch mehr Parameter unser Modell komplexer machen. Wenn die Annahmen der logistischen Regression erfüllt sind, folgt die Differenz der Log-Likelihoods von zwei Modellen einer $\chi^2$-Verteilung mit der Differenz der Parameteranzahl als Freiheitsgrade.

```{r Modellvergleich}
# Modellvergleich
anova(block1, block2, block3, block4)
```
Wir stellen an dieser Stelle also fest, dass die Aufnahme der Interaktionsterme in Block 3 und 4 nicht notwendig sind. Das Modell aus Block 2 ist nicht bedeutsam schlechter, als diese komplexeren Modelle. Die aufgestellten Hypothesen bezüglich der verstärkenden Effekte von ILOC bzw. schützenden Effekte von ELOC auf die Beziehung zwischen Rumination und Suizidalität scheinen also hier hinsichtlich der Ärger-Rumination keine Unterstützung zu finden. Betrachten wir aber das ausgewählte Modell (Block 2) genauer:

```{r Zusammenfassung-Block-2}}
# Ergebnisse
summary(block2)
```
Zur besseren Interpretierbarkeit ergänzen wir noch die Odds und deren Konfidenzintervalle:

```{r}
# Odds
results <- data.frame(Odds = exp(coef(block2)),
  Lower = exp(confint(block2)[, 1]),
  Upper = exp(confint(block2)[, 2])
)

# Ausgabe
results
```
Wir sehen anhand dieser Ergebnisse also, dass (jeweils bei Konstanthaltung der anderen Prädiktoren):

  1. Personen, die sich als nicht-heterosexuell identifizieren, eine um den Faktor `r round(exp(coef(block2)[2]), 2)` höhere Wahrscheinlichkeit haben, in der Vergangenheit Suizidgedanken gehabt zu haben, als heterosexuelle Personen.
  2. Sich für jede Einheit Unterschied in der Ärger-Rumination die Wahrscheinlichkeit, Suizidgedanken gehabt zu haben, um den Faktor `r round(exp(coef(block2)[3]), 2)` erhöht.
  3. Sich für jede Einheit Unterschied in der internalen Kontrollüberzeugung die Wahrscheinlichkeit, Suizidgedanken gehabt zu haben, um den Faktor `r round(exp(coef(block2)[4]), 2)` verringert.
  4. Der Grit einer Personen keinen bedeutsamen Einfluss auf die Wahrscheinlichkeit hat, Suizidgedanken gehabt zu haben.

Anhand der Modellvergleiche hatten wir schon gesehen, dass der Grit (anders als ursprünglich in den Hypothsen angenommen) keine moderierende Wirkung auf diese Einflüsse hat. Wenngleich die numerischen Ergebnisse von denen in [Lin et al. (2023)](https://doi.org/10.1016/j.jad.2023.02.148) abweichen, scheinen die Ergebnisse inhaltlich im Einklang zu sein.

### Klassifikationsgüte

Trotz diverser Vorschläge hat sich bislang kein generelles Effektstärkemaß im Sinne eines pseudo-$R^2$ zufriedenstellend durchsetzen können. Was sich hingegen, insbesondere aufgrund des rasanten Anstiegs von Machine-Learning-Verfahren, immer größerer Beliebtheit erfreut, sind Maße für die Klassifikations bzw. Vorhersagegüte. Eines der übersichtlichsten Konzepte ist dabei wahrscheinlich die treffend benannte _Confusion Matrix_. 

Für die Beurteilung der Klassifikationsgüte müssen wir zunächst die konkreten Vorhersagen aus dem Modell ableiten. Das hatten wir schon für die Darstellung der Wahrscheinlichkeiten gemacht, nur dass wir jetzt definitive Aussagen haben wollen. Dafür müssen wir festhalten, welche Wahrscheinlichkeit als welche Vorhersage klassifiziert wird. Im Normalfall können wir dabei so vorgehen, dass alle Vorhersagen $> .5$ als $\widehat{Y} = 1$ klassifiziert werden (und natürlich andersrum). Diese Vorhersagen stellen wir dann einfach den tatsächlich beobachteten Kategorien gegenüber:

```{r}
# Vorhersagen
idea$Prediction <- predict(block2, type = 'response') > .5
idea$Prediction <- factor(idea$Prediction, labels = c('None', 'Ideator'))

# Confusion
table(idea$Prediction, idea$Suicide)
```
Auf den ersten Blick scheint das nicht sonderlich zufriedenstellend. Das `caret` Paket bietet uns mit dem `confusionMatrix`-Befehl eine Möglichkeit dieses diffuse Gefühl der Unzufriedenheit numerisch auszudrücken:

```{r}
library(caret)
confusionMatrix(idea$Prediction, idea$Suicide)
```

```{r}
confuse <- table(idea$Prediction, idea$Suicide)
```

Im Fall der Vierfelder-Tafel sind die hier dargestellten Indikatoren relativ leicht rekonstruierbar. Die _Accuracy_ ist der relative Anteil der korrekt klassifizierten Personen (also $(`r  confuse[1,1]` + `r confuse[2,2]`) / `r sum(confuse)` = `r round(sum(diag(confuse))/sum(confuse), 3)`$ ). Die Accuracy wird allerdings ein schlechtes Maß, wenn die Kategorien sehr ungleich groß sind - etwas das bei der Vorhersage von Störungen sehr häufig vorkommt. Wenn z.B. nur 10% der Personen Suizidgedanken gehabt hätten, könnten wir bei jeder Person einfach raten, dass sie keine Suizidgedanken hatte und würden eine Accuracy von $.9$ erreichen. Um die Accuracy also ein bisschen zu relativieren erhalten wir z.B. die Aussage `No Information Rate` - also was unsere Accuracy gewesen wäre, hätten wir immer die häufigste Kategorie geraten (also die relative Häufigkeit der häufigsten Kategorie in den Daten). 

Für uns sind daher zunächst noch `Sensitivity` und `Specificity` von Interesse. Die Sensitivität ist in unserem Fall die relative Häufigkeit, mit der wir Personen, die keine Suizidgedanken hatten, auch korrekt als solche klassifizieren. Die `'Positive' Class: None` zeigt uns im Output, welche Kategorie hier als Referenz genutzt wird. Die Spezifität ist dann, im Gegenzug, die relative Häufigkeit mit der wir Personen, die Suizidgedanken hatten, als solche identifizieren können. Hier ist die Güte mit `r round(confuse[2,2] / sum(confuse[, 2]), 2)` sogar unter 50%. Wir können anhand unseres Modells also in weniger als der Hälfte der Fälle Personen mit Suizidgedanken korrekt identifizieren. Für die Prävention also eventuell noch kein optimales Modell.


## Multinomiale Logistische Regression

In der Studie von [Lin et al. (2023)](https://doi.org/10.1016/j.jad.2023.02.148) wird nicht nur zwischen Personen mit Suizidgedanken und Personen ohne Suizidgedanken unterschieden, sondern auch zusätzlich explizit Überlegungen zu den Unterschieden zwischen Personen mit Suizidgedanken (`Ideator`) und Personen mit Suizidversuchen (`Attempter`) angestellt. Insbesondere hinsichtlich des Grit, wird folgendes gesagt (S. 251):

> Grit is commonly viewed as a character strength in overcoming challenging circumstances.

Das wird zum Einen damit in Verbindung gebracht, dass Personen mit stärkerem Grit seltener Suizidgedanken hegen sollten (weil sie besser in Lage sind auf zukünftige Ziele zu fokussieren und diese auch gegen stärkeren Widerstand aufrecht zu erhalten). Zum Anderen findet sich aber eine gegensätzliche Überlegung hinsichtlich eines tatsächlichen Suizidversuchs:

> On the flip side, the ability to pursue death in the face of pain requires considerable persistence.

Daraus wird also zusammengenommen die erste Hypothese abgeleitet, die wir zu Beginn dieses Beitrags gesehen hatten:

> Given findings from past research, we hypothesize grit to be protective against the development of suicidal ideation, but associated with facilitating suicidal behaviors in the presence of ideation.

Um diese Hypothese untersuchen zu können, benötigen wir also eine Methode, mit der wir gleichzeitig alle drei Gruppen untersuchen können. Das erreichen wir durch die Erweiterung der logitischen Regression in die _multinomiale logistische Regression_. Diese Erweiterung geht zwar technisch gesehen mit einer sehr viel komplizierteren Rechnung einher als die bisher betrachtete Regression (weswegen wir sie auch nicht mehr über den `glm`-Befehl anstellen können), aber inhaltlich und konzeptuell ist sie eigentlich nur ein Zusatzschritt.

### Vorbereitung

Um die drei Gruppen unterscheiden zu können, müssen wir unsere Prädiktoren aus im gesamten Datensatz zentrieren und für die sexuelle Orientierung eine dichotomisierte Variable erstellen:

```{r}
# Zentrierung
grit$ARS_c <- scale(grit$ARS, scale = FALSE)
grit$ILOC_c <- scale(grit$ILOC, scale = FALSE)
grit$Grit_c <- scale(grit$Grit, scale = FALSE)

# dichotome Orientierung
grit$Orientation_bin <- factor(grit$Orientation, 
  labels = c('Hetero', 'LGBTQ', 'LGBTQ', 'LGBTQ'))
```

Um später einen Fehler in der `predict`-Funktion zu vermeiden, müssen wir unseren zentrierten Variablen hier noch ihre besonderen Fähigkeiten entziehen (der Fehler taucht immer mal wieder bei verschiedenen Paketen auf, wenn man zentrierte Variablen in `predict`-Funktionen verwendet, weswegen wir ihn hier direkt vermeiden):

```{r}
# Umwandlung in "numeric"
grit$ARS_c <- as.numeric(grit$ARS_c)
grit$ILOC_c <- as.numeric(grit$ILOC_c)
grit$Grit_c <- as.numeric(grit$Grit_c)
```


Außerdem müssen wir uns noch ein Paket besorgen, welches die multinomiale logistische Regression auch rechnen kann. Dafür gibt es zum Beispiel die funktion `multinom` im Paket `nnet`. Das Paket, wurde eigentlich dafür entwickelt, neuronale Netze zu rechnen. Aber in unserem Fall machen wir einfach nach dem ersten Schritt schluss (und verknüpfen unsere Regression nicht auch noch in einem Netz weiter).

```{r, eval = FALSE}
# Paket installieren
install.packages('nnet')
```

```{r}
# Paket laden
library(nnet)
```

### Modell

Wie schon im Abschnitt zur [einfachen logistischen Regression](#einfache-logistische-regression) getan, konzentrieren wir uns zunächst auf die explizite Hypothese, dass Grit die Wahrscheinlich von Suizidgedanken verringern, die von Suizidversuchen aber erhöhen sollte. Die `multinom`-Funktion kann man im Wesentlichen genauso benutzen wie die `lm`- oder `glm`-Funktionen:

```{r}
# Multinomiale logistische Regression
mod2 <- multinom(Suicide ~ 1 + Grit_c, grit)
```

Die Ausgabe unterscheidet sich allerdings ein wenig:

```{r}
# Ergebnisse aus multinom
summary(mod2)
```

Aus Gewohnheit des Lesens psychologischer, wissenschaftlicher Artikel fällt Ihnen eventuell als Erstes auf, dass hier kein $p$-Wert generiert wird. Aber auch die Gesamtstruktur unterscheidet sich ein wenig. Wir erhalten zwei Matrizen, eine enthält die Parameterschätzer (wieder im Logit-Format) und eine enthält die Standardfehler. In diesen beiden Matrizen zeigen die Zeilen die jeweilige Kategorie an, die vorhergesagt wird (in unserem Fall `Ideator` und `Attempter`). Die Spalten zeigen die Gewichte (bzw. Standardfehler) der jeweiligen Prädiktoren (hier nur das Intercept und `Grit_c`). 

Wenn wir die Ergebnisse wieder in Odds überführen, können wir mit der Interpretation genauso verfahren, wie schon bei der "normalen" logistischen Regression:

```{r}
# Odds
odds <- exp(coef(mod2))

odds
```

Im ersten Intercept wird hier also festgehalten, wie viel wahrscheinlicher es ist, dass eine Person ein `Ideator` ist, als dass sie bislang weder Suizidgedanken noch -versuche hatte (`none` ist unsere Referenzkategorie), wenn sie durchschnittlichen Grit vorweisen kann (wir haben `Grit` zentriert). Im zweiten Intercept steht das Gleiche, aber für die Wahrscheinlichkeit, dass eine Person ein `Attempter` ist. Bezüglich des Grit können wir sagen, dass für jede zusätzliche Einheit in Grit, eine um das `r round(odds[1, 2],2)`-fache geringere Wahrscheinlichkeit erwartet wird, dass eine Person schon einmal Suizidgedanken hatte.

### Vorhesagen und Abbildungen

Wie schon bei der logistischen Regression, kann es immens hilfreiche sein, sich konkrete Vorhersagen anzusehen und eventuell eine Abbildung zu erstellen. Erneut können wir mit `predict` direkt Wahrscheinlichkeiten erzeugen lassen:

```{r}
# Mittlerer Grit +/- 1 und 2 SD
new_data <- data.frame(Grit_c = c(-2*sd(grit$Grit), -sd(grit$Grit), 0, sd(grit$Grit), 2*sd(grit$Grit)))

# Vorhegesagte Wahrscheinlichkeiten
new_data$Probability <- predict(mod2, newdata = new_data, type = 'probs')

# Ausgabe
new_data
```

Wir sehen hier also, dass jetzt die Wahrscheinlichkeit für alle drei Kategorien bestimmt wird. Etwas bildlicher (der Code für die Abbildung ist wieder in der begleitenden R-Datei enthalten):

```{r Abbildung-Multinomiale-Logistische-Regression, fig = TRUE, echo = FALSE, warning=FALSE, message=FALSE, height=4, width=4}
# Daten und Vorhersagen erstellen
plottable <- data.frame(Grit_c = seq(min(grit$Grit_c), max(grit$Grit_c), .01))
plottable <- cbind(plottable, predict(mod2, newdata = plottable, type = 'probs'))

# Ins long-format umstellen (reshape)
plottable <- reshape(plottable, 
  direction = 'long', 
  varying = 2:4, 
  v.names = 'Probability', timevar = 'Category', times = c('None', 'Ideator', 'Attempter'))

# Plot erstellen
ggplot(plottable, aes(x = Grit_c, y = Probability, color = Category)) +
  geom_line() +
  theme_pandar() +
  scale_color_pandar() +
  ylim(0, 1)
```
Wie man sieht steigt mit mehr Grit die Wahrscheinlichkeit, als `None` klassifiziert zu werden, während die Wahrscheinlichkeiten für die beiden anderen Kategorien sinkt. Bisher sprechen die Ergebnisse also nur für die erste Hälfte der Hypothese.

### Inferenzstatistik

Die Ergebnisse des `multinom`-Befehls liefern Parameterschätzer und Standardfehler. Die Konfidenzintervall der Parameter können wir allerdings - wie bei allen anderen Regressionen - mit dem `confint`-Befehl bestimmen:

```{r}
confint(mod2)
```

Weil die Ergebnisse im Logit-Format sind, müssen wir hier gegen 0 prüfen. In beiden Fällen ist die 0 nicht im Konfidenzintervall enthalten - mehr Grit geht also mit einer _statistisch bedeutsam_ geringeren Wahrscheinlichkeit einher, Suizidgedanken und -versuche durchlebt zu haben.

Um einen $p$-Wert zu erzeugen, müssen wir den $z$-Test händisch durchführen. Wie im [allersten Test](/lehre/statistik-i/tests-konfidenzintervalle), den Sie im Bachelorstudium kennengelernt haben, ergibt sich die Teststatistik aus dem Verhältnis aus Parameter zum Standardfehler

$$
z = \frac{\beta}{\mathbb{SE}(\beta)}
$$
Wenn die Annahmen der multinomialen logistischen Regression halten, folgt dieser Wert asymptotisch einer Standardnormalverteilung, also können wir den $p$-Wert direkt bestimmen. Sowohl Parameter als auch Standardfehler können wir aus der `summary` des Modells ziehen:

```{r}
# Parameter
beta <- summary(mod2)$coefficients

# Standardfehler
se <- summary(mod2)$standard.errors


# z-Werte
z <- beta/se

# p-Werte (zweiseitig)
p <- 2 * pnorm(abs(z), lower.tail = FALSE)
```

### Volle Modelle

Um die, im Artikel von [Lin et al. (2023)](https://doi.org/10.1016/j.jad.2023.02.148) gezeigten Ergebnisse zu reproduzieren, müssen wir wieder die vier separaten Blöcke aufstellen und vergleichen. Im Artikel werden dann die Odds und deren Konfidenzintervalle aus dem vollen Modell berichtet.

```{r}
# Blöcke aufstellen
block1 <- multinom(Suicide ~ 1 + Orientation_bin, 
  grit)
block2 <- multinom(Suicide ~ 1 + Orientation_bin + ARS_c + ILOC_c + Grit_c,
  grit)
block3 <- multinom(Suicide ~ 1 + Orientation_bin + ARS_c + ILOC_c + Grit_c +
    ARS_c:ILOC_c + ARS_c:Grit_c + ILOC_c:Grit_c,
  grit)
block4 <- multinom(Suicide ~ 1 + Orientation_bin + ARS_c + ILOC_c + Grit_c +
    ARS_c:ILOC_c + ARS_c:Grit_c + ILOC_c:Grit_c +
    ARS_c:ILOC_c:Grit_c,
  grit)

# Modellvergleiche
anova(block1, block2, block3, block4)
```
Die Vergleiche zeigen, dass zumindest die Hypothesen hinsichtlich der moderierenden Effekte keine Unterstüzung finden. Im Artikel werden dennoch die Ergebnisse des vollen Modells berichtet, welche wir hier kurz rekonstruieren können. 

Wie in den letzten beiden Sitzungen gesehen, bietet das Paket sjPlot eine breite Palette an Möglichkeiten, Ergebnisse schnell in die üblichen Tabellenformate für Artikel zu übertragen. Das gilt auch für die Ergebnisse aus `multinom`.

```{r}
library(sjPlot)

tab_model(block4, show.r2 = FALSE, show.aic = TRUE)
```
Wir haben in dieser Tabelle also die Ergebnisse, die in Tabelle 3, Model 1 in den ersten beiden Spalten dargestellt sind. Weil sich die Wahrscheinlichkeit der dritten Kategorie direkt aus den Wahrscheinlichkeiten für die ersten beiden Gruppen ergibt, werden hier nur die Vergleiche von `Ideator` und `Attempter` mit der Referenz `none` dargestellt. Um einen direkten Vergleich der beiden Gruppen zu erhalten, können wir das Referenzlevel einfach mit dem `relevel`-Befehl ändern:

```{r}
# Referenzlevel ändern
grit$Suicide_r <- relevel(grit$Suicide, ref = 'Attempter')

# Modell
block4b <- multinom(Suicide_r ~ 1 + Orientation_bin + ARS_c + ILOC_c + Grit_c +
    ARS_c:ILOC_c + ARS_c:Grit_c + ILOC_c:Grit_c +
    ARS_c:ILOC_c:Grit_c,
  grit)

# Tabelle
tab_model(block4b, show.r2 = FALSE, show.aic = TRUE)
```

Am AIC können wir sehen, dass beide Modelle identische Passung zu den Daten aufweisen - also einfach Umformulierungen voneinander sind. 

Im Artikel zwar nicht dargestellt, aber auch für multinomiale logistische Regression interessant ist die Klassifikationsgüte, welche wir für die reguläre logistische Regression anhand der Confusion Matrix untersucht hatten. Das gleiche Vorgehen können wir auch hier nutzen. Wenn wir `predict` auf ein `multinom`-Ergebnis anwenden, erhalten wir direkt die vorhergesagte Kategorie:

```{r}
# Vorgesagte Kateogrien
grit$Prediction <- predict(block4)

# Confusion Matrix
confusionMatrix(grit$Prediction, grit$Suicide)
```
```{r, echo = FALSE}
tab <- table(grit$Prediction, grit$Suicide)
```

Erneut gibt die `Accuracy` den relativen Anteil der korrekt klassifzierten Personen an. In unserem Fall also $(`r tab[1,1]` + `r tab[2,2]` + `r tab[3, 3]`) / `r sum(tab)` = `r round(sum(diag(tab))/sum(tab),2)`$. Senisitivtät und Spezifität werden jetzt ein wenig anders interpretiert als im Fall der binären logistischen Regression. Für die Klasse der `Ideator`, zum Beispiel, wurden `r tab[2,2]` der insgesamt `r sum(tab[,2])` Personen korrekt als Personen mit Suizidgedanken identifiziert (`r round(tab[2,2] / sum(tab[,2]),3)*100`%). So _sensitiv_ ist unser Modell also in der Detektion dieser Gruppe. Auf der anderen Seite sind `r tab[2,2]` der insgesamt `r sum(tab[2,])` (`r round(tab[2,2] / sum(tab[2,]),3)*100`%) der Personen, für die `Ideator` vorhergesagt wurde auch tatsächlich Personen, die Suizidgedanken berichtet haben. So _spezifisch_ ist unsere Vorhersage also für diese Gruppe.

## Abschluss

Mit den gezeigten Schritten (und einer zusätzlichen Korrelationstablle via `corr.test`) können wir also versuchen alle Ergebnisse aus dem Artikel von [Lin et al. (2023)](https://doi.org/10.1016/j.jad.2023.02.148) zu reproduzieren. Wie Sie (als aufmerksame Lerser*innen) bestimmt mitbekommen haben, sind dieser Ergebnisse allerdings nicht identisch. Zwar zweigen die Ergebnisse für das "Model 1" aus dem Artikel die gleichen Muster an bedeutsamen und nicht-bedeutsamen Prädiktoren, die tatsächlichen Zahlen weichen allerdings ab. Ich habe die Autorinnen des Papers kontaktiert, um über die Diskrepranzen zu sprechen. Meine Vermutung ist dabei, dass die Unterschiede auf den Ausschluss von Ausreißern und Extremwerten zurückgehen, welche im Paper (und dem ursprünglichen Skript auf dem OSF) nicht dokumentiert sind. Leider hat diese Kontaktaufnahme dazu geführt, dass der Beitrag im OSF verschwunden ist, bis diese Diskrepanzen geklärt werden können, sodass es mir zum Zeitpunkt, zu dem ich diesen Beitrag schreibe nicht möglich ist, eine definitive Aussage dazu zu treffen, woher diese Unterschiede kommen. Dennoch sind Sie jetzt in der Lage, für die anderen drei berichteten Modelle zu prüfen, ob es auch dort zu solchen Diskrepanzen kommt und ob sich die Interpretation im Artikel dadurch verändern würden.


***

## Literatur
[Eid, M., Gollwitzer, M., & Schmitt, M. (2017).](https://ubffm.hds.hebis.de/Record/HEB366849158) *Statistik und Forschungsmethoden* (5. Auflage, 1. Auflage: 2010). Weinheim: Beltz.

[Lin, Y.-C., O'Connell, K.L., & Law, K.C. (2023).](https://doi.org/10.1016/j.jad.2023.02.148) Moderating roles of grit and locus of control on rumination and suicidality. *Journal of Affective Disorders, 330*, 250-258. doi: 10.1016/j.jad.2023.02.148.

[Pituch, K. A. & Stevens, J. P. (2016).](https://ubffm.hds.hebis.de/Record/HEB371183324) *Applied Multivariate Statistics for the Social Sciences* (6th ed.). New York: Taylor & Francis.



* <small> *Blau hinterlegte Autor:innenangaben führen Sie direkt zur universitätsinternen Ressource.* </small>
